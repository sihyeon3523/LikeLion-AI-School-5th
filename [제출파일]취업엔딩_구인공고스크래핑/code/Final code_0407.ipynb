{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51caf7a4",
   "metadata": {},
   "source": [
    "# [ë¯¸ì…˜] \"ì¸ê³µì§€ëŠ¥\", \"ë°ì´í„°\" ì—°ê´€ ì±„ìš©ê³µê³  í¬ë¡¤ë§í•˜ê¸°\n",
    "## ì°¸ê°€íŒ€ ì†Œê°œ\n",
    "* íŒ€ëª…: ì·¨ì—…ì—”ë”©ğŸŒ¸\n",
    "* íŒ€ì›: ì´ì‹œí˜„, ìœ ì§„ì•„, ê¹€í•˜ê²½, ê¹€ìœ¤ë¯¼, ê¹€ë‚˜ë¦¬\n",
    "* ë‚´ìš© ì†Œê°œ: <br>\n",
    "ì í• í™ˆí˜ì´ì§€ë¥¼ í†µí•´ 'ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´', 'ì¸ê³µì§€ëŠ¥/ë¨¸ì‹ ëŸ¬ë‹' í¬ì§€ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ <br>\n",
    "íŠ¹ì • ì—°ì°¨ ê²½ë ¥ì˜ ì±„ìš© ê³µê³ ë¥¼ ìŠ¤í¬ë©í•‘í•´ì˜¤ë©°, (ì‹ ì…, 1ë…„ì°¨, 2ë…„ì°¨ ë“± ê°ê°) <br>\n",
    "ì¶”ê°€ì ìœ¼ë¡œ í•´ë‹¹ ì±„ìš© ê³µê³ ì˜ íšŒì‚¬ í‰ì  ì •ë³´ë¥¼<br>\n",
    "ì¡í”Œë˜ë‹› ì‚¬ì´íŠ¸ì—ì„œ ë”°ë¡œ ê°€ì ¸ì™€ì„œ í•˜ë‚˜ì˜ ì—‘ì…€íŒŒì¼ë¡œ ë§Œë“œëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì˜€ë‹¤.<br>\n",
    "\n",
    "* ì‚¬ìš© ë°ì´í„°:\n",
    "    - ì í• : íšŒì‚¬ëª…, ê³µê³ ëª…, ê¸°ìˆ ìŠ¤íƒ, ì£¼ìš”ì—…ë¬´ , ìê²©ìš”ê±´, ì§€ì›ë§ˆê°ì¼ ë“±..\n",
    "    - ì¡í”Œë˜ë‹› : íšŒì‚¬ í‰ì \n",
    "    \n",
    "* ìŠ¤í¬ë˜í•‘ ì¡°ê±´:\n",
    "    -  'ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´', 'ì¸ê³µì§€ëŠ¥/ë¨¸ì‹ ëŸ¬ë‹' í¬ì§€ì…˜ë§Œ\n",
    "    -  ê²½ë ¥ ì¡°ê±´ì„ í•¨ìˆ˜ì˜ input ë°ì´í„°ë¡œ í•˜ì—¬ ì‹ ì…, 1ë…„, 2ë…„ ë“± ì—‘ì…€íŒŒì¼ë§ˆë‹¤ ë‹¨ì¼í•˜ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê²Œí•¨.\n",
    "    - ê²°ê³¼ íŒŒì¼ì€ ì‹ ì…, 1ë…„ì°¨ ì±„ìš© ê³µê³  ìŠ¤í¬ë˜í•‘ íŒŒì¼ì„ ì²¨ë¶€í•¨.\n",
    "* ìŠ¤í¬ë˜í•‘ ë°©ë²•:\n",
    "    - ì…€ë ˆë‹ˆì›€ì„ í†µí•´ ê°€ìƒ ì›¹ë¸Œë¼ìš°ì €ë¡œ ì ‘ê·¼í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510b5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970a1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager # ìë™ìœ¼ë¡œ chrome driver ë‹¤ìš´ë¡œë“œ ìš© \n",
    "from selenium.webdriver.chrome.service import Service # ë‹¤ìš´ë¡œë“œëœ í¬ë¡¬ë“œë¼ì´ë²„ íŒŒì¼ì„ ì—°ê²°í•˜ê¸° ìœ„í•´ í™œìš©\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ë¶ˆí•„ìš”í•œ Warning ë©”ì‹œì§€ë¥¼ êº¼ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07358f4",
   "metadata": {},
   "source": [
    "### 1. í¬ë¡¬ ê°€ìƒ ë“œë¼ì´ë¸Œ ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041fa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [/Users/hk/.wdm/drivers/chromedriver/mac64/100.0.4896.60/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path = ChromeDriverManager().install())\n",
    "\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a7ba6",
   "metadata": {},
   "source": [
    "### 2. ì¡í”Œë˜ë‹› ìŠ¤í¬ë˜í•‘ ì½”ë“œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceef067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¡í”Œë˜ë‹› ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜\n",
    "def job_planet_scraping(company):\n",
    "    url = \"https://www.jobplanet.co.kr/search?query=\" + company\n",
    "    \n",
    "    # ì‚¬ì´íŠ¸ ì°¨ë‹¨ ëŒ€ë¹„ ìœ ì € ì •ë³´\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.60 Safari/537.36'}\n",
    "\n",
    "    res = requests.get(url, headers=headers).content\n",
    "    soup = BeautifulSoup(res,'html.parser')\n",
    "    \n",
    "    # í¬ë¡¤ë§ ì—ëŸ¬ë‚  ê²½ìš° 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    rate = \"ì •ë³´ì—†ìŒ\"\n",
    "    \n",
    "    try:\n",
    "        # í‰ì  ê¸ì–´ì˜¤ê¸°\n",
    "        star = soup.find('span',{'class':'rate_ty02'})\n",
    "        # í‰ì  ìˆ«ìë§Œ ë‚˜ì˜¤ë„ë¡ ìˆ˜ì •\n",
    "        rate = star.get_text()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c2ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf19a921",
   "metadata": {},
   "source": [
    "### 3. ì „ì²´ ìŠ¤í¬ë˜í•‘ ì½”ë“œ í•¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09f729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(year):    \n",
    "    # ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´, ì¸ê³µì§€ëŠ¥/ë¨¸ì‹ ëŸ¬ë‹, ì‹ ì… \n",
    "    df = pd.DataFrame({'jobpost_url':[],\n",
    "                  'skill_stack':[]})\n",
    "    \n",
    "    url = \"https://www.jumpit.co.kr/positions?jobCategory=8&career={}\".format(year)\n",
    "    print(df)\n",
    "    \n",
    "    driver.get(url)\n",
    "    print(driver.current_url)\n",
    "\n",
    "    # ê³„ì† ìŠ¤í¬ë¡¤ ë‹¤ìš´í•˜ë©´ì„œ ë°ì´í„°ë¥¼ ë‹¤ ì¡°íšŒí•  ë•Œ\n",
    "    SCROLL_PAUSE_SEC = 1\n",
    "\n",
    "    # ìŠ¤í¬ë¡¤ ë†’ì´ ê°€ì ¸ì˜´\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(last_height)\n",
    "\n",
    "    while True:\n",
    "        # ëê¹Œì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´ \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # 1ì´ˆ ëŒ€ê¸°\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "        # ìŠ¤í¬ë¡¤ ë‹¤ìš´ í›„ ìŠ¤í¬ë¡¤ ë†’ì´ ë‹¤ì‹œ ê°€ì ¸ì˜´\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        print(new_height, last_height)\n",
    "        if new_height == last_height:\n",
    "            time.sleep(SCROLL_PAUSE_SEC)\n",
    "            break # while ë¬¸ì„ ë‚˜ê°€ì„œ last_height ì—…ë°ì´íŠ¸ \n",
    "        last_height = new_height\n",
    "    # ìŠ¤í¬ë¡¤ í•œ ë’¤ ë‹¤ì‹œ web html ê°€ì ¸ì˜¤ê¸° \n",
    "    web = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # ì „ì²´ ê³µê³  ë‚´ìš© \n",
    "    # positions = web.find_all('div', {'class':'sc-dJjYzT jtdhQb'})\n",
    "    positions = web.find_all('div', {'class':'sc-dlVxhl fUeray'})\n",
    "\n",
    "    #company_name = []\n",
    "    #jobposting_name = []\n",
    "    jobposting_url = []\n",
    "    skill_stack = []\n",
    "\n",
    "    for position in positions:\n",
    "        url = position.find('a', {'target':'_self'}).attrs['href'] # ê³µê³  url \n",
    "        #skill = position.find('ul', {'class':'sc-fKVqWL jcccsQ'}).get_text().split()\n",
    "        skill = position.find('ul', {'class':'sc-iwjdpV keRuBz'}).get_text().split()\n",
    "\n",
    "        tmp = {'jobpost_url': url, 'skill_stack': skill}\n",
    "\n",
    "        df = df.append(tmp, ignore_index = True)\n",
    "        #position.find('img').attrs['alt'] # íšŒì‚¬ëª… \n",
    "        #position.find('h2', {'class':'position_card_info_title'}).get_text() # ê³µê³ ëª…\n",
    "    print(\"url ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "    print(df)\n",
    "    \n",
    "    df['jobpost_name'] = ['0']*len(df) # ê³µê³ ëª… \n",
    "    df['company_name'] = ['0']*len(df) # ê¸°ì—…ëª… \n",
    "    \n",
    "    # ì—¬ê¸°ì— ì¶”ê°€ -ì¡í”Œë˜ë‹›\n",
    "    df['company_star'] = ['0']*len(df) # ê¸°ì—… í‰ì \n",
    "    \n",
    "    df['task'] = ['0']*len(df) # ì£¼ìš”ì—…ë¬´\n",
    "    df['qualification'] = ['0']*len(df) # ìê²©ìš”ê±´\n",
    "    df['treatment'] = ['0']*len(df) # ìš°ëŒ€ì‚¬í•­\n",
    "    df['welfare'] = ['0']*len(df) # ë³µì§€ ë° í˜œíƒ\n",
    "    df['end_day'] = ['0']*len(df) # ë§ˆê°ì¼\n",
    "    df['education'] = ['0']*len(df) # í•™ë ¥ \n",
    "\n",
    "    #ì „ì²´ ê³µê³ ë³„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° \n",
    "    position_url = 'https://www.jumpit.co.kr'\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # ê³µê³  ê°ê°ì— ì ‘ê·¼ \n",
    "        new_url = position_url + df.at[i, 'jobpost_url']\n",
    "        print(new_url)\n",
    "\n",
    "        driver.get(new_url)\n",
    "        time.sleep(1)\n",
    "        new_web = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # ê³µê³ ëª… \n",
    "        jobpost_name = new_web.find('h1').get_text()\n",
    "        #print(jobpost_name)\n",
    "        df.at[i, 'jobpost_name'] = jobpost_name\n",
    "\n",
    "        # ê¸°ì—…ëª… \n",
    "        #comp_name = new_web.find('div', {'class':'styles_position_title_box_desc__uvEoB'}).get_text()\n",
    "        comp_name = new_web.find('div', {'class':'position_title_box_desc'}).get_text()\n",
    "        #print(comp_name)\n",
    "        df.at[i, 'company_name'] = comp_name\n",
    "        \n",
    "        # ì—¬ê¸°ì— ì¶”ê°€ -ì¡í”Œë˜ë‹›\n",
    "        star = job_planet_scraping(comp_name)\n",
    "        df.at[i, 'company_star'] = star\n",
    "\n",
    "\n",
    "        # ì£¼ìš”ì—…ë¬´\n",
    "        #task = new_web.find_all('dl', {'class':'styles_root__FK3fp'})[1].pre.get_text()\n",
    "        task = new_web.find_all('dl', {'class':'sc-gWXbKe hvgMyA'})[1].pre.get_text()\n",
    "        task = task.replace('\\n', '')\n",
    "        df.at[i, 'task'] = task\n",
    "\n",
    "        # ìê²©ìš”ê±´\n",
    "        #qualification =new_web.find_all('dl', {'class':'styles_root__FK3fp'})[2].pre.get_text()\n",
    "        qualification =new_web.find_all('dl', {'class':'sc-gWXbKe hvgMyA'})[2].pre.get_text()\n",
    "        qualification = qualification.replace('\\n', '')\n",
    "        df.at[i, 'qualification'] = qualification\n",
    "\n",
    "        # ìš°ëŒ€ì‚¬í•­\n",
    "        #treat =new_web.find_all('dl', {'class':'styles_root__FK3fp'})[3].pre.get_text()\n",
    "        treat =new_web.find_all('dl', {'class':'sc-gWXbKe hvgMyA'})[3].pre.get_text()\n",
    "        treat = treat.replace('\\n','')\n",
    "        df.at[i, 'treatment'] = treat\n",
    "\n",
    "        # ë³µì§€ ë° í˜œíƒ\n",
    "        #wel =new_web.find_all('dl', {'class':'styles_root__FK3fp'})[4].pre.get_text()\n",
    "        wel =new_web.find_all('dl', {'class':'sc-gWXbKe hvgMyA'})[4].pre.get_text()\n",
    "        wel = wel.replace('\\n','')\n",
    "        df.at[i, 'welfare'] = wel\n",
    "\n",
    "        # í•™ë ¥ \n",
    "        edu = new_web.find_all('dl', {\"class\":\"styles_item__LhiHT\"})[1].dd.get_text() \n",
    "        df.at[i, 'education'] = edu\n",
    "\n",
    "        # ë§ˆê°ì¼\n",
    "        end_day = new_web.find_all('dl', {\"class\":\"styles_item__LhiHT\"})[2].dd.get_text()\n",
    "        df.at[i, 'end_day'] = end_day\n",
    "        \n",
    "        # ê²½ë ¥\n",
    "        if year == 0 : \n",
    "            year = 'ì‹ ì…'\n",
    "        df.at[i, 'career'] = int(year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390909ee",
   "metadata": {},
   "source": [
    "year == 0 (ì‹ ì… ê²½ë ¥) ì¼ ë•Œì˜ ì±„ìš© ê³µê³  ìŠ¤í¬ë˜í•‘í•˜ì—¬ ì €ì¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1adf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [jobpost_url, skill_stack]\n",
      "Index: []\n",
      "https://www.jumpit.co.kr/positions?jobCategory=8&career=0\n",
      "1908\n",
      "3197 1908\n",
      "4539 3197\n",
      "5858 4539\n",
      "6529 5858\n",
      "6529 6529\n",
      "url ìˆ˜ì§‘ ì™„ë£Œ\n",
      "       jobpost_url                                        skill_stack\n",
      "0   /position/8084          [swÂ·, machinelearningÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, python]\n",
      "1   /position/6132  [c#Â·, pythonÂ·, pytorchÂ·, tensorflowÂ·, kerasÂ·, ...\n",
      "2   /position/8022     [pythonÂ·, pytorchÂ·, tensorflowÂ·, deeplearning]\n",
      "3   /position/7255  [pythonÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, machinelearningÂ·, rÂ·, awsÂ·...\n",
      "4   /position/5411  [tensorflowÂ·, pytorchÂ·, linuxÂ·, pythonÂ·, ai/ì¸ê³µì§€ëŠ¥]\n",
      "..             ...                                                ...\n",
      "66  /position/3637                       [pythonÂ·, deeplearningÂ·, sw]\n",
      "67  /position/2763  [deeplearningÂ·, tensorflowÂ·, c++Â·, javaÂ·, pyth...\n",
      "68  /position/2405              [c++Â·, pythonÂ·, tensorflowÂ·, pytorch]\n",
      "69  /position/1761  [c++Â·, c#Â·, opencvÂ·, communicationÂ·, visual, s...\n",
      "70  /position/1322               [machinelearningÂ·, pythonÂ·, ai/ì¸ê³µì§€ëŠ¥]\n",
      "\n",
      "[71 rows x 2 columns]\n",
      "https://www.jumpit.co.kr/position/8084\n",
      "https://www.jumpit.co.kr/position/6132\n",
      "https://www.jumpit.co.kr/position/8022\n",
      "https://www.jumpit.co.kr/position/7255\n",
      "https://www.jumpit.co.kr/position/5411\n",
      "https://www.jumpit.co.kr/position/7628\n",
      "https://www.jumpit.co.kr/position/8052\n",
      "https://www.jumpit.co.kr/position/3139\n",
      "https://www.jumpit.co.kr/position/8050\n",
      "https://www.jumpit.co.kr/position/4202\n",
      "https://www.jumpit.co.kr/position/4201\n",
      "https://www.jumpit.co.kr/position/7709\n",
      "https://www.jumpit.co.kr/position/5986\n",
      "https://www.jumpit.co.kr/position/7422\n",
      "https://www.jumpit.co.kr/position/8009\n",
      "https://www.jumpit.co.kr/position/7557\n",
      "https://www.jumpit.co.kr/position/2555\n",
      "https://www.jumpit.co.kr/position/7890\n",
      "https://www.jumpit.co.kr/position/6533\n",
      "https://www.jumpit.co.kr/position/3908\n",
      "https://www.jumpit.co.kr/position/7779\n",
      "https://www.jumpit.co.kr/position/7556\n",
      "https://www.jumpit.co.kr/position/7555\n",
      "https://www.jumpit.co.kr/position/7808\n",
      "https://www.jumpit.co.kr/position/4227\n",
      "https://www.jumpit.co.kr/position/5422\n",
      "https://www.jumpit.co.kr/position/1067\n",
      "https://www.jumpit.co.kr/position/4043\n",
      "https://www.jumpit.co.kr/position/6834\n",
      "https://www.jumpit.co.kr/position/7006\n",
      "https://www.jumpit.co.kr/position/3614\n",
      "https://www.jumpit.co.kr/position/4518\n",
      "https://www.jumpit.co.kr/position/4854\n",
      "https://www.jumpit.co.kr/position/4883\n",
      "https://www.jumpit.co.kr/position/6959\n",
      "https://www.jumpit.co.kr/position/6888\n",
      "https://www.jumpit.co.kr/position/3747\n",
      "https://www.jumpit.co.kr/position/5827\n",
      "https://www.jumpit.co.kr/position/6586\n",
      "https://www.jumpit.co.kr/position/6149\n",
      "https://www.jumpit.co.kr/position/6587\n",
      "https://www.jumpit.co.kr/position/6585\n",
      "https://www.jumpit.co.kr/position/6345\n",
      "https://www.jumpit.co.kr/position/6503\n",
      "https://www.jumpit.co.kr/position/6267\n",
      "https://www.jumpit.co.kr/position/3609\n",
      "https://www.jumpit.co.kr/position/6150\n",
      "https://www.jumpit.co.kr/position/6147\n",
      "https://www.jumpit.co.kr/position/6043\n",
      "https://www.jumpit.co.kr/position/612\n",
      "https://www.jumpit.co.kr/position/5871\n",
      "https://www.jumpit.co.kr/position/5722\n",
      "https://www.jumpit.co.kr/position/5534\n",
      "https://www.jumpit.co.kr/position/4880\n",
      "https://www.jumpit.co.kr/position/4032\n",
      "https://www.jumpit.co.kr/position/4882\n",
      "https://www.jumpit.co.kr/position/4916\n",
      "https://www.jumpit.co.kr/position/3203\n",
      "https://www.jumpit.co.kr/position/3202\n",
      "https://www.jumpit.co.kr/position/4447\n",
      "https://www.jumpit.co.kr/position/3548\n",
      "https://www.jumpit.co.kr/position/4276\n",
      "https://www.jumpit.co.kr/position/4158\n",
      "https://www.jumpit.co.kr/position/2619\n",
      "https://www.jumpit.co.kr/position/4132\n",
      "https://www.jumpit.co.kr/position/2887\n",
      "https://www.jumpit.co.kr/position/3637\n",
      "https://www.jumpit.co.kr/position/2763\n",
      "https://www.jumpit.co.kr/position/2405\n",
      "https://www.jumpit.co.kr/position/1761\n",
      "https://www.jumpit.co.kr/position/1322\n"
     ]
    }
   ],
   "source": [
    "df_0 = scraping(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e006ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.to_csv(\"career_0_result.csv\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e002b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobpost_url</th>\n",
       "      <th>skill_stack</th>\n",
       "      <th>jobpost_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_star</th>\n",
       "      <th>task</th>\n",
       "      <th>qualification</th>\n",
       "      <th>treatment</th>\n",
       "      <th>welfare</th>\n",
       "      <th>end_day</th>\n",
       "      <th>education</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/position/8084</td>\n",
       "      <td>[swÂ·, machinelearningÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, python]</td>\n",
       "      <td>ì§ˆë³‘ì¹˜ë£Œ ê´€ë ¨ ê°œë°œ ì—°êµ¬ì›(ì‹ ì…~3ë…„)</td>\n",
       "      <td>ë„·íƒ€ê²Ÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>â€¢ ëª¨ì§‘ë¶„ì•¼: Systems Biology, Computational Biology...</td>\n",
       "      <td>â€¢ ì„ì‚¬ ì´ìƒâ€¢ ì‹ ì…~3ë…„ ê²½ë ¥</td>\n",
       "      <td>â€¢ ì œì•½íšŒì‚¬/ë°”ì´ì˜¤í… ê·¼ë¬´ ê²½ë ¥ ì„ í˜¸\\t\\t\\t\\t\\t\\t\\t\\t\\tâ€¢ ì‹œìŠ¤í…œìƒë¬¼í•™...</td>\n",
       "      <td>â€¢ ê°œì¸ ì¥ë¹„ ì§€ì›: ìµœê³ ê¸‰ PC ë° ë…¸íŠ¸ë¶, êµ¬ê¸€í´ë¼ìš°ë“œ ë° ìì²´ì„œë²„ ì§€ì›, ì‚¬ë¬´...</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>ì„ì‚¬ì¡¸ì—… ì´ìƒ</td>\n",
       "      <td>ì‹ ì…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/position/6132</td>\n",
       "      <td>[c#Â·, pythonÂ·, pytorchÂ·, tensorflowÂ·, kerasÂ·, ...</td>\n",
       "      <td>ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì´ë¯¸ì§€ í”„ë¡œì„¸ì‹± ê°œë°œì</td>\n",
       "      <td>ì—íƒ€ë§¥ìŠ¤</td>\n",
       "      <td>2.9</td>\n",
       "      <td>â€¢ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ë°˜ë„ì²´, LED ì†Œì ê²°í•¨ ê²€ì¶œ ì—°êµ¬ ê°œë°œ</td>\n",
       "      <td>â€¢ ê´€ë ¨ ì „ê³µ ì„ì‚¬ ì´ìƒ</td>\n",
       "      <td>â€¢ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬ í”„ë¡œì íŠ¸ ê²½í—˜ìâ€¢ Object Detection, Image...</td>\n",
       "      <td>â€¢ ì£¼ 1íšŒ ì¬íƒê·¼ë¬´ ê°€ëŠ¥â€¢ ì£¼ 5ì¼ ìœ ì—° ê·¼ë¬´ì œ ìš´ìš©, ëˆˆì¹˜ë³´ì´ì§€ ì•ŠëŠ” ììœ ë¡œìš´ ...</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>ì„ì‚¬ì¡¸ì—… ì´ìƒ</td>\n",
       "      <td>ì‹ ì…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/position/8022</td>\n",
       "      <td>[pythonÂ·, pytorchÂ·, tensorflowÂ·, deeplearning]</td>\n",
       "      <td>[ì „ë¬¸ì—°êµ¬ìš”ì›] ìƒì„±ëª¨ë¸ ì—°êµ¬ ë° ì œí’ˆ ê°œë°œì ëª¨ì§‘</td>\n",
       "      <td>ì†”íŠ¸ë£©ìŠ¤</td>\n",
       "      <td>2.8</td>\n",
       "      <td>â€¢ ìƒì„± ëª¨ë¸ ì—°êµ¬ ë° ì œí’ˆ ê°œë°œ   - GAN ì‘ìš© ì—°êµ¬(ì…ëª¨ì–‘ ë° í¬ì¦ˆ ìƒì„±) ...</td>\n",
       "      <td>â€¢ í•™ë ¥ : ì„ì‚¬í•™ìœ„ ì´ìƒâ€¢ ê²½ë ¥ : ì‹ ì…~ê²½ë ¥ 3ë…„â€¢ ê¸°ìˆ ìŠ¤íƒ : python(p...</td>\n",
       "      <td>â€¢ ê´€ë ¨ ì „ê³µ ì´ìˆ˜ â€¢ Openpose/Mmposeë¥¼ í™œìš©í•œ ì—°êµ¬ ë° ê°œë°œ â€¢ SO...</td>\n",
       "      <td>â€¢ ì„ì§ì› ë° ê°€ì¡± ì˜ë£Œë¹„ ë° ê±´ê°•ê²€ì§„ ì§€ì›â€¢ 5ì„±ê¸‰ í˜¸í…” ìˆ™ë°•ë£Œ ì§€ì›â€¢ íšŒì‹ë¹„ ë°...</td>\n",
       "      <td>ìƒì‹œ</td>\n",
       "      <td>ì„ì‚¬ì¡¸ì—… ì´ìƒ(ì¡¸ì—…ì˜ˆì •ì ê°€ëŠ¥)</td>\n",
       "      <td>ì‹ ì…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/position/7255</td>\n",
       "      <td>[pythonÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, machinelearningÂ·, rÂ·, awsÂ·...</td>\n",
       "      <td>ê°œë°œ ì—­ëŸ‰ì´ ìˆëŠ” AI/Data Engineer</td>\n",
       "      <td>ì¿¤í…</td>\n",
       "      <td>4.1</td>\n",
       "      <td>â€¢ AI / Data ì»¨ì„¤íŒ… - ê¸°ì—… ëŒ€ìƒ DataOps, MLOps ì»¨ì„¤íŒ… - ë¨¸...</td>\n",
       "      <td>â€¢ ì»´í“¨í„°ê³µí•™, ë°ì´í„°, AI, ìˆ˜í•™/í†µê³„í•™ ë“± ì „ì‚°ê³„ì—´ ì „ê³µìâ€¢ ê°œë°œ ê²½í—˜</td>\n",
       "      <td>â€¢ í†µê³„ì  ê¸°ë²•ì„ í†µí•œ ë°ì´í„° ë¶„ì„ ì—­ëŸ‰â€¢ R/Python í”„ë¡œê·¸ë˜ë° ë° ê¸°ë³¸ì ì¸ ...</td>\n",
       "      <td>â€¢ ì¿¤í…ì€ ììœ ë¡œìš´ ë¶„ìœ„ê¸° ì•ˆì—ì„œ ë³¸ì¸ì´ ë§¡ì€ ì—­í• ê³¼ ì±…ì„ì„ ë‹¤í•˜ëŠ” ì—…ë¬´ í™˜ê²½ì„ ì§€...</td>\n",
       "      <td>ìƒì‹œ</td>\n",
       "      <td>ëŒ€í•™êµì¡¸ì—…(4ë…„) ì´ìƒ</td>\n",
       "      <td>ì‹ ì…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/position/5411</td>\n",
       "      <td>[tensorflowÂ·, pytorchÂ·, linuxÂ·, pythonÂ·, ai/ì¸ê³µì§€ëŠ¥]</td>\n",
       "      <td>[ì„ì‚¬ì´ìƒ] AI Engineer</td>\n",
       "      <td>ë¼ì˜¨ë°ì´í„°</td>\n",
       "      <td>5.0</td>\n",
       "      <td>â€¢ Natural Language / Vision / Audio ë“± ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜...</td>\n",
       "      <td>â€¢ ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ë¶„ì•¼ ì„/ë°•ì‚¬ í•™ìœ„ [í•„ìˆ˜]â€¢ ìˆ˜ìŠµê¸°ê°„ : 3ê°œì›”â€¢ ê¸°ë³¸ì ì¸ Li...</td>\n",
       "      <td>â€¢ í•™ì› / íŠœí„°ë§ í”„ë¡œê·¸ë¨ì„ ì œì™¸í•œ ìµœì‹  ì¸ê³µì§€ëŠ¥ ê¸°ë²•ì„ í™œìš©í•œ ì„œë¹„ìŠ¤ / í”„ë¡œì ...</td>\n",
       "      <td>â€¢ ì½”ì–´ê·¼ë¬´ì œ - 11:30ë¶„ ì¶œê·¼ / ììœ¨ í‡´ê·¼â€¢ ëª¨ë“  íŒ€ì›ê°„ì˜ ìˆ˜í‰ì ì¸ ê´€ê³„â€¢ ...</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>ì„ì‚¬ì¡¸ì—… ì´ìƒ(ì¡¸ì—…ì˜ˆì •ì ê°€ëŠ¥)</td>\n",
       "      <td>ì‹ ì…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobpost_url                                        skill_stack  \\\n",
       "0  /position/8084          [swÂ·, machinelearningÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, python]   \n",
       "1  /position/6132  [c#Â·, pythonÂ·, pytorchÂ·, tensorflowÂ·, kerasÂ·, ...   \n",
       "2  /position/8022     [pythonÂ·, pytorchÂ·, tensorflowÂ·, deeplearning]   \n",
       "3  /position/7255  [pythonÂ·, ai/ì¸ê³µì§€ëŠ¥Â·, machinelearningÂ·, rÂ·, awsÂ·...   \n",
       "4  /position/5411  [tensorflowÂ·, pytorchÂ·, linuxÂ·, pythonÂ·, ai/ì¸ê³µì§€ëŠ¥]   \n",
       "\n",
       "                   jobpost_name company_name company_star  \\\n",
       "0         ì§ˆë³‘ì¹˜ë£Œ ê´€ë ¨ ê°œë°œ ì—°êµ¬ì›(ì‹ ì…~3ë…„)          ë„·íƒ€ê²Ÿ          0.0   \n",
       "1           ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì´ë¯¸ì§€ í”„ë¡œì„¸ì‹± ê°œë°œì         ì—íƒ€ë§¥ìŠ¤          2.9   \n",
       "2  [ì „ë¬¸ì—°êµ¬ìš”ì›] ìƒì„±ëª¨ë¸ ì—°êµ¬ ë° ì œí’ˆ ê°œë°œì ëª¨ì§‘         ì†”íŠ¸ë£©ìŠ¤          2.8   \n",
       "3    ê°œë°œ ì—­ëŸ‰ì´ ìˆëŠ” AI/Data Engineer           ì¿¤í…          4.1   \n",
       "4            [ì„ì‚¬ì´ìƒ] AI Engineer        ë¼ì˜¨ë°ì´í„°          5.0   \n",
       "\n",
       "                                                task  \\\n",
       "0  â€¢ ëª¨ì§‘ë¶„ì•¼: Systems Biology, Computational Biology...   \n",
       "1                 â€¢ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ë°˜ë„ì²´, LED ì†Œì ê²°í•¨ ê²€ì¶œ ì—°êµ¬ ê°œë°œ   \n",
       "2  â€¢ ìƒì„± ëª¨ë¸ ì—°êµ¬ ë° ì œí’ˆ ê°œë°œ   - GAN ì‘ìš© ì—°êµ¬(ì…ëª¨ì–‘ ë° í¬ì¦ˆ ìƒì„±) ...   \n",
       "3  â€¢ AI / Data ì»¨ì„¤íŒ… - ê¸°ì—… ëŒ€ìƒ DataOps, MLOps ì»¨ì„¤íŒ… - ë¨¸...   \n",
       "4  â€¢ Natural Language / Vision / Audio ë“± ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜...   \n",
       "\n",
       "                                       qualification  \\\n",
       "0                                  â€¢ ì„ì‚¬ ì´ìƒâ€¢ ì‹ ì…~3ë…„ ê²½ë ¥   \n",
       "1                                      â€¢ ê´€ë ¨ ì „ê³µ ì„ì‚¬ ì´ìƒ   \n",
       "2  â€¢ í•™ë ¥ : ì„ì‚¬í•™ìœ„ ì´ìƒâ€¢ ê²½ë ¥ : ì‹ ì…~ê²½ë ¥ 3ë…„â€¢ ê¸°ìˆ ìŠ¤íƒ : python(p...   \n",
       "3         â€¢ ì»´í“¨í„°ê³µí•™, ë°ì´í„°, AI, ìˆ˜í•™/í†µê³„í•™ ë“± ì „ì‚°ê³„ì—´ ì „ê³µìâ€¢ ê°œë°œ ê²½í—˜   \n",
       "4  â€¢ ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ë¶„ì•¼ ì„/ë°•ì‚¬ í•™ìœ„ [í•„ìˆ˜]â€¢ ìˆ˜ìŠµê¸°ê°„ : 3ê°œì›”â€¢ ê¸°ë³¸ì ì¸ Li...   \n",
       "\n",
       "                                           treatment  \\\n",
       "0  â€¢ ì œì•½íšŒì‚¬/ë°”ì´ì˜¤í… ê·¼ë¬´ ê²½ë ¥ ì„ í˜¸\\t\\t\\t\\t\\t\\t\\t\\t\\tâ€¢ ì‹œìŠ¤í…œìƒë¬¼í•™...   \n",
       "1  â€¢ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬ í”„ë¡œì íŠ¸ ê²½í—˜ìâ€¢ Object Detection, Image...   \n",
       "2  â€¢ ê´€ë ¨ ì „ê³µ ì´ìˆ˜ â€¢ Openpose/Mmposeë¥¼ í™œìš©í•œ ì—°êµ¬ ë° ê°œë°œ â€¢ SO...   \n",
       "3  â€¢ í†µê³„ì  ê¸°ë²•ì„ í†µí•œ ë°ì´í„° ë¶„ì„ ì—­ëŸ‰â€¢ R/Python í”„ë¡œê·¸ë˜ë° ë° ê¸°ë³¸ì ì¸ ...   \n",
       "4  â€¢ í•™ì› / íŠœí„°ë§ í”„ë¡œê·¸ë¨ì„ ì œì™¸í•œ ìµœì‹  ì¸ê³µì§€ëŠ¥ ê¸°ë²•ì„ í™œìš©í•œ ì„œë¹„ìŠ¤ / í”„ë¡œì ...   \n",
       "\n",
       "                                             welfare     end_day  \\\n",
       "0  â€¢ ê°œì¸ ì¥ë¹„ ì§€ì›: ìµœê³ ê¸‰ PC ë° ë…¸íŠ¸ë¶, êµ¬ê¸€í´ë¼ìš°ë“œ ë° ìì²´ì„œë²„ ì§€ì›, ì‚¬ë¬´...  2022-05-03   \n",
       "1  â€¢ ì£¼ 1íšŒ ì¬íƒê·¼ë¬´ ê°€ëŠ¥â€¢ ì£¼ 5ì¼ ìœ ì—° ê·¼ë¬´ì œ ìš´ìš©, ëˆˆì¹˜ë³´ì´ì§€ ì•ŠëŠ” ììœ ë¡œìš´ ...  2022-05-07   \n",
       "2  â€¢ ì„ì§ì› ë° ê°€ì¡± ì˜ë£Œë¹„ ë° ê±´ê°•ê²€ì§„ ì§€ì›â€¢ 5ì„±ê¸‰ í˜¸í…” ìˆ™ë°•ë£Œ ì§€ì›â€¢ íšŒì‹ë¹„ ë°...          ìƒì‹œ   \n",
       "3  â€¢ ì¿¤í…ì€ ììœ ë¡œìš´ ë¶„ìœ„ê¸° ì•ˆì—ì„œ ë³¸ì¸ì´ ë§¡ì€ ì—­í• ê³¼ ì±…ì„ì„ ë‹¤í•˜ëŠ” ì—…ë¬´ í™˜ê²½ì„ ì§€...          ìƒì‹œ   \n",
       "4  â€¢ ì½”ì–´ê·¼ë¬´ì œ - 11:30ë¶„ ì¶œê·¼ / ììœ¨ í‡´ê·¼â€¢ ëª¨ë“  íŒ€ì›ê°„ì˜ ìˆ˜í‰ì ì¸ ê´€ê³„â€¢ ...  2022-04-29   \n",
       "\n",
       "           education career  \n",
       "0            ì„ì‚¬ì¡¸ì—… ì´ìƒ     ì‹ ì…  \n",
       "1            ì„ì‚¬ì¡¸ì—… ì´ìƒ     ì‹ ì…  \n",
       "2  ì„ì‚¬ì¡¸ì—… ì´ìƒ(ì¡¸ì—…ì˜ˆì •ì ê°€ëŠ¥)     ì‹ ì…  \n",
       "3       ëŒ€í•™êµì¡¸ì—…(4ë…„) ì´ìƒ     ì‹ ì…  \n",
       "4  ì„ì‚¬ì¡¸ì—… ì´ìƒ(ì¡¸ì—…ì˜ˆì •ì ê°€ëŠ¥)     ì‹ ì…  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82157",
   "metadata": {},
   "source": [
    "year == 1(1ë…„ì°¨ ê²½ë ¥) ì¼ ë•Œì˜ ì±„ìš© ê³µê³  ìŠ¤í¬ë˜í•‘í•˜ì—¬ ì €ì¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = scraping(1)\n",
    "df_1.to_csv(\"career_1_result.csv\", index = False, encoding=\"utf-8-sig\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c97521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd5164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef977bc",
   "metadata": {},
   "source": [
    "### 5. í¬ë¡¬ ê°€ìƒ ë¸Œë¼ìš°ì € ë‹«ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f29524",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27961947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
